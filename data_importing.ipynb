{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Method 1: The Direct Pandas Way (Easiest) ---\n",
      "Successfully loaded data using Method 1:\n",
      "  Parking Occupancy : Fall 2025 Week 0 Unnamed: 1         Unnamed: 2  \\\n",
      "0         Thursday, September 25, 2025        NaN                NaN   \n",
      "1                           Space Type        NaN           Location   \n",
      "2                                    A  Structure               8980   \n",
      "3                                    A        NaN             Athena   \n",
      "4                                    A        NaN  Campus Point East   \n",
      "\n",
      "         Unnamed: 3 Unnamed: 4 Unnamed: 5 Unnamed: 6  \n",
      "0  Available Spaces        NaN        NaN        NaN  \n",
      "1           8:00 AM   10:00 AM   12:00 PM    2:00 PM  \n",
      "2                25         23         19         20  \n",
      "3               217        140        108        112  \n",
      "4                94         23         13         17  \n",
      "\n",
      "==================================================\n",
      "\n",
      "--- Method 2: The 'requests' Way (More control) ---\n",
      "Download successful (Status 200)\n",
      "Successfully loaded data using Method 2:\n",
      "  Parking Occupancy : Fall 2025 Week 0 Unnamed: 1         Unnamed: 2  \\\n",
      "0         Thursday, September 25, 2025        NaN                NaN   \n",
      "1                           Space Type        NaN           Location   \n",
      "2                                    A  Structure               8980   \n",
      "3                                    A        NaN             Athena   \n",
      "4                                    A        NaN  Campus Point East   \n",
      "\n",
      "         Unnamed: 3 Unnamed: 4 Unnamed: 5 Unnamed: 6  \n",
      "0  Available Spaces        NaN        NaN        NaN  \n",
      "1           8:00 AM   10:00 AM   12:00 PM    2:00 PM  \n",
      "2                25         23         19         20  \n",
      "3               217        140        108        112  \n",
      "4                94         23         13         17  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "\n",
    "# This is the special URL you created that exports the Google Sheet as a CSV.\n",
    "# これは、GoogleスプレッドシートをCSVとしてエクスポートするためにあなたが作成した特別なURLです。\n",
    "csv_url = \"https://docs.google.com/spreadsheets/d/1OscrXVHgOn75NrsrUxJfitmcPBHRj6xlnRcsq9jXo2g/export?format=csv&gid=590671728\"\n",
    "\n",
    "print(\"--- Method 1: The Direct Pandas Way (Easiest) ---\")\n",
    "# --- 方法1：Pandasで直接読み込む方法（最も簡単）---\n",
    "\n",
    "try:\n",
    "    # Pandas can read a CSV directly from a URL.\n",
    "    # PandasはURLから直接CSVを読み込むことができます。\n",
    "    df_method1 = pd.read_csv(csv_url)\n",
    "    \n",
    "    # Print the first 5 rows to check the data.\n",
    "    # 最初の5行を印刷してデータを確認します。\n",
    "    print(\"Successfully loaded data using Method 1:\")\n",
    "    print(df_method1.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Method 1 failed: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"--- Method 2: The 'requests' Way (More control) ---\")\n",
    "# --- 方法2：「requests」ライブラリを使う方法（より制御が効く）---\n",
    "# This method is better if you want to check if the download was successful\n",
    "# or handle errors.\n",
    "# この方法は、ダウンロードが成功したか確認したり、エラーを処理したりしたい場合に優れています。\n",
    "\n",
    "try:\n",
    "    # First, download the content from the URL.\n",
    "    # まず、URLからコンテンツをダウンロードします。\n",
    "    response = requests.get(csv_url)\n",
    "    \n",
    "    # Check if the download was successful (Status code 200 means OK).\n",
    "    # ダウンロードが成功したか確認します（ステータスコード 200 は OK を意味します）。\n",
    "    if response.status_code == 200:\n",
    "        print(\"Download successful (Status 200)\")\n",
    "        \n",
    "        # The content is in text format. We need to convert it into a\n",
    "        # file-like object that pandas can read.\n",
    "        # コンテンツはテキスト形式です。これをpandasが読み取れる\n",
    "        # ファイルのようなオブジェクトに変換する必要があります。\n",
    "        csv_content = response.content.decode('utf-8')\n",
    "        csv_file_like_object = io.StringIO(csv_content)\n",
    "        \n",
    "        # Now, read this \"file\" with pandas.\n",
    "        # この「ファイル」をpandasで読み込みます。\n",
    "        df_method2 = pd.read_csv(csv_file_like_object)\n",
    "        \n",
    "        print(\"Successfully loaded data using Method 2:\")\n",
    "        print(df_method2.head())\n",
    "        \n",
    "        # Now you have the data in a DataFrame (df_method2)\n",
    "        # これで、データがDataFrame (df_method2) に格納されました。\n",
    "        # You can start your analysis:\n",
    "        # ここから分析を開始できます：\n",
    "        # print(df_method2.describe())\n",
    "        \n",
    "    else:\n",
    "        # If the status code isn't 200, something went wrong.\n",
    "        # ステータスコードが200でない場合、何かがうまくいきませんでした。\n",
    "        print(f\"Error: Download failed with status code {response.status_code}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Method 2 failed: {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parking Occupancy : Fall 2025 Week 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thursday, September 25, 2025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Available Spaces</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Space Type</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Location</td>\n",
       "      <td>8:00 AM</td>\n",
       "      <td>10:00 AM</td>\n",
       "      <td>12:00 PM</td>\n",
       "      <td>2:00 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>Structure</td>\n",
       "      <td>8980</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Athena</td>\n",
       "      <td>217</td>\n",
       "      <td>140</td>\n",
       "      <td>108</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Campus Point East</td>\n",
       "      <td>94</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Visitor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P510</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Visitor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P602</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Visitor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P603</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Visitor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P703</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Visitor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P752</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Parking Occupancy : Fall 2025 Week 0 Unnamed: 1         Unnamed: 2  \\\n",
       "0           Thursday, September 25, 2025        NaN                NaN   \n",
       "1                             Space Type        NaN           Location   \n",
       "2                                      A  Structure               8980   \n",
       "3                                      A        NaN             Athena   \n",
       "4                                      A        NaN  Campus Point East   \n",
       "..                                   ...        ...                ...   \n",
       "107                              Visitor        NaN               P510   \n",
       "108                              Visitor        NaN               P602   \n",
       "109                              Visitor        NaN               P603   \n",
       "110                              Visitor        NaN               P703   \n",
       "111                              Visitor        NaN               P752   \n",
       "\n",
       "           Unnamed: 3 Unnamed: 4 Unnamed: 5 Unnamed: 6  \n",
       "0    Available Spaces        NaN        NaN        NaN  \n",
       "1             8:00 AM   10:00 AM   12:00 PM    2:00 PM  \n",
       "2                  25         23         19         20  \n",
       "3                 217        140        108        112  \n",
       "4                  94         23         13         17  \n",
       "..                ...        ...        ...        ...  \n",
       "107                 4          2          0          0  \n",
       "108                 7          2          0          1  \n",
       "109                22         12          5         12  \n",
       "110                 9         10          8          9  \n",
       "111                 0          0          0          0  \n",
       "\n",
       "[112 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_method1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching main page: https://transportation.ucsd.edu/commute/permits/availability.html\n",
      "Successfully fetched main page.\n",
      "Found 12 <iframe> tags. Filtering for Google Sheets...\n",
      "Found 12 unique Google Sheet tabs to download.\n",
      "\n",
      "Downloading data for GID: 590671728\n",
      "  [SUCCESS] GID '590671728' loaded with 112 rows.\n",
      "\n",
      "Downloading data for GID: 1596814157\n",
      "  [SUCCESS] GID '1596814157' loaded with 112 rows.\n",
      "\n",
      "Downloading data for GID: 0\n",
      "  [SUCCESS] GID '0' loaded with 113 rows.\n",
      "\n",
      "Downloading data for GID: 1732410273\n",
      "  [SUCCESS] GID '1732410273' loaded with 113 rows.\n",
      "\n",
      "Downloading data for GID: 980526681\n",
      "  [SUCCESS] GID '980526681' loaded with 110 rows.\n",
      "\n",
      "Downloading data for GID: 1691861364\n",
      "  [SUCCESS] GID '1691861364' loaded with 110 rows.\n",
      "\n",
      "Downloading data for GID: 1701491299\n",
      "  [SUCCESS] GID '1701491299' loaded with 110 rows.\n",
      "\n",
      "Downloading data for GID: 1997138837\n",
      "  [SUCCESS] GID '1997138837' loaded with 110 rows.\n",
      "\n",
      "Downloading data for GID: 1843964475\n",
      "  [SUCCESS] GID '1843964475' loaded with 110 rows.\n",
      "\n",
      "Downloading data for GID: 871989841\n",
      "  [SUCCESS] GID '871989841' loaded with 110 rows.\n",
      "\n",
      "Downloading data for GID: 1378029010\n",
      "  [FAILED] Could not download GID 1378029010. Status: 404\n",
      "\n",
      "Downloading data for GID: 293064621\n",
      "  [FAILED] Could not download GID 293064621. Status: 404\n",
      "\n",
      "==================================================\n",
      "Scraping complete.\n",
      "Successfully downloaded 10 tables.\n",
      "\n",
      "--- Data from GID '590671728' ---\n",
      "  Parking Occupancy : Fall 2025 Week 0 Unnamed: 1         Unnamed: 2  \\\n",
      "0         Thursday, September 25, 2025        NaN                NaN   \n",
      "1                           Space Type        NaN           Location   \n",
      "2                                    A  Structure               8980   \n",
      "3                                    A        NaN             Athena   \n",
      "4                                    A        NaN  Campus Point East   \n",
      "\n",
      "         Unnamed: 3 Unnamed: 4 Unnamed: 5 Unnamed: 6  \n",
      "0  Available Spaces        NaN        NaN        NaN  \n",
      "1           8:00 AM   10:00 AM   12:00 PM    2:00 PM  \n",
      "2                25         23         19         20  \n",
      "3               217        140        108        112  \n",
      "4                94         23         13         17  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "import time\n",
    "from bs4 import BeautifulSoup # You'll need to install this: pip install beautifulsoup4\n",
    "import re\n",
    "\n",
    "# --- 1. Scrape the main page to find all the Google Sheet links ---\n",
    "# --- 1. メインページをスクレイピングして、すべてのGoogleスプレッドシートのリンクを見つけます ---\n",
    "\n",
    "# The main page we want to parse\n",
    "# 解析したいメインページ\n",
    "main_url = \"https://transportation.ucsd.edu/commute/permits/availability.html\"\n",
    "\n",
    "# This dictionary will hold all our data\n",
    "# この辞書がすべてのデータを保持します\n",
    "all_dataframes = {}\n",
    "\n",
    "print(f\"Fetching main page: {main_url}\")\n",
    "# メインページを取得中: {main_url}\n",
    "\n",
    "try:\n",
    "    # Get the HTML content of the main page\n",
    "    # メインページのHTMLコンテンツを取得します\n",
    "    main_page_response = requests.get(main_url)\n",
    "    \n",
    "    if main_page_response.status_code == 200:\n",
    "        print(\"Successfully fetched main page.\")\n",
    "        # メインページの取得に成功しました。\n",
    "        \n",
    "        # Parse the HTML with BeautifulSoup\n",
    "        # BeautifulSoupでHTMLを解析します\n",
    "        soup = BeautifulSoup(main_page_response.content, 'html.parser')\n",
    "        \n",
    "        # Find all <iframe> tags in the HTML\n",
    "        # HTML内のすべての <iframe> タグを見つけます\n",
    "        iframes = soup.find_all('iframe')\n",
    "        \n",
    "        print(f\"Found {len(iframes)} <iframe> tags. Filtering for Google Sheets...\")\n",
    "        # {len(iframes)} 個の <iframe> タグを見つけました。Googleスプレッドシートでフィルタリング中...\n",
    "\n",
    "        # Store the unique CSV links we find\n",
    "        # 見つかったユニークなCSVリンクを保存します\n",
    "        csv_links = {}\n",
    "\n",
    "        for frame in iframes:\n",
    "            # Get the 'src' attribute from the iframe tag\n",
    "            # iframeタグから 'src' 属性を取得します\n",
    "            src_link = frame.get('src')\n",
    "            \n",
    "            # Check if it's a Google Sheet /pubhtml link\n",
    "            # これがGoogleスプレッドシートの /pubhtml リンクか確認します\n",
    "            if src_link and 'docs.google.com/spreadsheets' in src_link and '/pubhtml' in src_link:\n",
    "                \n",
    "                # --- 2. Convert the /pubhtml link to a /export?format=csv link ---\n",
    "                # --- 2. /pubhtml リンクを /export?format=csv リンクに変換します ---\n",
    "                \n",
    "                # We need to extract the Sheet ID and the GID\n",
    "                # シートIDとGIDを抽出する必要があります\n",
    "                \n",
    "                # Extract Sheet ID\n",
    "                # e.g., .../d/1OscrXVHgOn75NrsrUxJfitmcPBHRj6xlnRcsq9jXo2g/pubhtml...\n",
    "                sheet_id_match = re.search(r'/d/([a-zA-Z0-9-_]+)', src_link)\n",
    "                \n",
    "                # Extract GID\n",
    "                # e.g., ...gid=590671728...\n",
    "                gid_match = re.search(r'gid=([0-9]+)', src_link)\n",
    "                \n",
    "                if sheet_id_match and gid_match:\n",
    "                    sheet_id = sheet_id_match.group(1)\n",
    "                    gid = gid_match.group(1)\n",
    "                    \n",
    "                    # Create the unique CSV download link\n",
    "                    # ユニークなCSVダウンロードリンクを作成します\n",
    "                    csv_url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&gid={gid}\"\n",
    "                    \n",
    "                    # Add it to our list, using the GID as a key to avoid duplicates\n",
    "                    # 重複を避けるためにGIDをキーとしてリストに追加します\n",
    "                    csv_links[gid] = csv_url\n",
    "\n",
    "        print(f\"Found {len(csv_links)} unique Google Sheet tabs to download.\")\n",
    "        # ダウンロードするユニークなGoogleスプレッドシートのタブを {len(csv_links)} 個見つけました。\n",
    "\n",
    "        # --- 3. Loop and Download each CSV ---\n",
    "        # --- 3. 各CSVをループしてダウンロードします ---\n",
    "        for gid, download_url in csv_links.items():\n",
    "            \n",
    "            print(f\"\\nDownloading data for GID: {gid}\")\n",
    "            # GID: {gid} のデータをダウンロード中\n",
    "            \n",
    "            try:\n",
    "                response = requests.get(download_url)\n",
    "                if response.status_code == 200:\n",
    "                    csv_content = response.content.decode('utf-8')\n",
    "                    csv_file = io.StringIO(csv_content)\n",
    "                    \n",
    "                    df = pd.read_csv(csv_file)\n",
    "                    \n",
    "                    # We'll store the data using the GID as the key\n",
    "                    # GIDをキーとしてデータを保存します\n",
    "                    all_dataframes[gid] = df\n",
    "                    \n",
    "                    print(f\"  [SUCCESS] GID '{gid}' loaded with {len(df)} rows.\")\n",
    "                    #   [成功] GID '{gid}' に {len(df)} 行が読み込まれました。\n",
    "                else:\n",
    "                    print(f\"  [FAILED] Could not download GID {gid}. Status: {response.status_code}\")\n",
    "                    #   [失敗] GID {gid} をダウンロードできませんでした。ステータス: {response.status_code}\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"  [FAILED] An error occurred for GID {gid}: {e}\")\n",
    "                #   [失敗] GID {gid} でエラーが発生しました: {e}\n",
    "            \n",
    "            time.sleep(1) # Be polite\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to fetch main page. Status code: {main_page_response.status_code}\")\n",
    "        # メインページの取得に失敗しました。ステータスコード: {main_page_response.status_code}\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    # エラーが発生しました: {e}\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Scraping complete.\")\n",
    "# スクレイピングが完了しました。\n",
    "print(f\"Successfully downloaded {len(all_dataframes)} tables.\")\n",
    "# {len(all_dataframes)} 個のテーブルを正常にダウンロードしました。\n",
    "\n",
    "# --- 4. NOW YOU CAN USE THE DATA ---\n",
    "# --- 4. これでデータを使用できます ---\n",
    "if all_dataframes:\n",
    "    first_gid = list(all_dataframes.keys())[0]\n",
    "    print(f\"\\n--- Data from GID '{first_gid}' ---\")\n",
    "    # GID '{first_gid}' からのデータ ---\n",
    "    print(all_dataframes[first_gid].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parking Occupancy : Fall 2025 Week 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thursday, September 25, 2025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Available Spaces</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Space Type</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Location</td>\n",
       "      <td>8:00 AM</td>\n",
       "      <td>10:00 AM</td>\n",
       "      <td>12:00 PM</td>\n",
       "      <td>2:00 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>Structure</td>\n",
       "      <td>8980</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Athena</td>\n",
       "      <td>217</td>\n",
       "      <td>140</td>\n",
       "      <td>108</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Campus Point East</td>\n",
       "      <td>94</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Visitor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P510</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Visitor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P602</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Visitor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P603</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Visitor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P703</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Visitor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P752</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Parking Occupancy : Fall 2025 Week 0 Unnamed: 1         Unnamed: 2  \\\n",
       "0           Thursday, September 25, 2025        NaN                NaN   \n",
       "1                             Space Type        NaN           Location   \n",
       "2                                      A  Structure               8980   \n",
       "3                                      A        NaN             Athena   \n",
       "4                                      A        NaN  Campus Point East   \n",
       "..                                   ...        ...                ...   \n",
       "107                              Visitor        NaN               P510   \n",
       "108                              Visitor        NaN               P602   \n",
       "109                              Visitor        NaN               P603   \n",
       "110                              Visitor        NaN               P703   \n",
       "111                              Visitor        NaN               P752   \n",
       "\n",
       "           Unnamed: 3 Unnamed: 4 Unnamed: 5 Unnamed: 6  \n",
       "0    Available Spaces        NaN        NaN        NaN  \n",
       "1             8:00 AM   10:00 AM   12:00 PM    2:00 PM  \n",
       "2                  25         23         19         20  \n",
       "3                 217        140        108        112  \n",
       "4                  94         23         13         17  \n",
       "..                ...        ...        ...        ...  \n",
       "107                 4          2          0          0  \n",
       "108                 7          2          0          1  \n",
       "109                22         12          5         12  \n",
       "110                 9         10          8          9  \n",
       "111                 0          0          0          0  \n",
       "\n",
       "[112 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dataframes['590671728']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading raw data for GID: 590671728...\n",
      "Raw data downloaded. Starting interactive cleaning...\n",
      "  Found Date: Thursday, September 25, 2025\n",
      "  Found Time: 8:00 AM\n",
      "  Found Header at row index: 2\n",
      "  Set new header.\n",
      "  Cleaned column names.\n",
      "  Added metadata columns.\n",
      "  Dropped empty rows.\n",
      "  Converted data types.\n",
      "\n",
      "==================================================\n",
      "--- FINAL CLEANED DATA (First 10 Rows) ---\n",
      "2  Space_Type        nan           Location 8:00_AM 10:00_AM 12:00_PM 2:00_PM  \\\n",
      "3           A  Structure               8980      25       23       19      20   \n",
      "4           A        NaN             Athena     217      140      108     112   \n",
      "5           A        NaN  Campus Point East      94       23       13      17   \n",
      "6           A        NaN  Campus Point West       1        0        0       1   \n",
      "7           A        NaN             Gilman     326      120       44      45   \n",
      "8           A        NaN            Hopkins     110       96       72      83   \n",
      "9           A        NaN             Pangea      57       44       34      37   \n",
      "10          A        NaN           Scholars     231      212      194     184   \n",
      "11          A        NaN              South     358      259      184     153   \n",
      "12          A        NaN              TDLLN     225      119      103     106   \n",
      "\n",
      "2        Date Time_of_Reading Source_GID  \n",
      "3  2025-09-25         8:00 AM  590671728  \n",
      "4  2025-09-25         8:00 AM  590671728  \n",
      "5  2025-09-25         8:00 AM  590671728  \n",
      "6  2025-09-25         8:00 AM  590671728  \n",
      "7  2025-09-25         8:00 AM  590671728  \n",
      "8  2025-09-25         8:00 AM  590671728  \n",
      "9  2025-09-25         8:00 AM  590671728  \n",
      "10 2025-09-25         8:00 AM  590671728  \n",
      "11 2025-09-25         8:00 AM  590671728  \n",
      "12 2025-09-25         8:00 AM  590671728  \n",
      "\n",
      "--- FINAL DATA INFO ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 110 entries, 3 to 112\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   Space_Type       110 non-null    object        \n",
      " 1   nan              11 non-null     object        \n",
      " 2   Location         110 non-null    object        \n",
      " 3   8:00_AM          108 non-null    object        \n",
      " 4   10:00_AM         108 non-null    object        \n",
      " 5   12:00_PM         108 non-null    object        \n",
      " 6   2:00_PM          108 non-null    object        \n",
      " 7   Date             110 non-null    datetime64[ns]\n",
      " 8   Time_of_Reading  110 non-null    object        \n",
      " 9   Source_GID       110 non-null    object        \n",
      "dtypes: datetime64[ns](1), object(9)\n",
      "memory usage: 8.7+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "import re\n",
    "\n",
    "# --- 1. Download the single raw DataFrame for testing ---\n",
    "# --- 1. テスト用の単一の生DataFrameをダウンロード ---\n",
    "\n",
    "target_gid = '590671728'\n",
    "sheet_id = '1OscrXVHgOn75NrsrUxJfitmcPBHRj6xlnRcsq9jXo2g'\n",
    "download_url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&gid={target_gid}\"\n",
    "\n",
    "print(f\"Downloading raw data for GID: {target_gid}...\")\n",
    "# GID: {target_gid} の生データをダウンロード中...\n",
    "\n",
    "try:\n",
    "    response = requests.get(download_url)\n",
    "    if response.status_code == 200:\n",
    "        csv_content = response.content.decode('utf-8')\n",
    "        csv_file = io.StringIO(csv_content)\n",
    "        \n",
    "        # Read with no header, this is our raw, messy data\n",
    "        # ヘッダーなしで読み込みます。これが生の、整理されていないデータです\n",
    "        raw_df = pd.read_csv(csv_file, header=None)\n",
    "        \n",
    "        print(\"Raw data downloaded. Starting interactive cleaning...\")\n",
    "        # 生データをダウンロードしました。対話型クリーニングを開始します...\n",
    "\n",
    "        # --- 2. Start Interactive Cleaning ---\n",
    "        # --- 2. 対話型クリーニングの開始 ---\n",
    "\n",
    "        # --- Step 2a: Find Date and Time ---\n",
    "        # --- ステップ2a: 日付と時刻の検索 ---\n",
    "        date_str = None\n",
    "        time_str = None\n",
    "        header_row_index = None\n",
    "\n",
    "        df_string_dump = raw_df.to_string()\n",
    "        date_match = re.search(r'(\\w+,\\s\\w+\\s\\d+,\\s\\d{4})', df_string_dump)\n",
    "        if date_match:\n",
    "            date_str = date_match.group(1)\n",
    "            print(f\"  Found Date: {date_str}\")\n",
    "            #   日付が見つかりました: {date_str}\n",
    "\n",
    "        time_match = re.search(r'(\\d{1,2}:\\d{2}\\s[AP]M)', df_string_dump)\n",
    "        if time_match:\n",
    "            time_str = time_match.group(1)\n",
    "            print(f\"  Found Time: {time_str}\")\n",
    "            #   時刻が見つかりました: {time_str}\n",
    "\n",
    "        # --- Step 2b: Find Header Row ---\n",
    "        # --- ステップ2b: ヘッダー行の検索 ---\n",
    "        for i, row in raw_df.iterrows():\n",
    "            if 'Location' in row.values:\n",
    "                header_row_index = i\n",
    "                print(f\"  Found Header at row index: {header_row_index}\")\n",
    "                #   ヘッダー行をインデックス: {header_row_index} で見つけました\n",
    "                break\n",
    "        \n",
    "        if header_row_index is None:\n",
    "            raise ValueError(\"Could not find header row with 'Location'\")\n",
    "            # 'Location' を含むヘッダー行が見つかりませんでした\n",
    "\n",
    "        # --- Step 2c: Create Clean DataFrame ---\n",
    "        # --- ステップ2c: クリーンなDataFrameの作成 ---\n",
    "        new_header = raw_df.iloc[header_row_index]\n",
    "        clean_df = raw_df[header_row_index + 1:].copy()\n",
    "        clean_df.columns = new_header\n",
    "        print(\"  Set new header.\")\n",
    "        #   新しいヘッダーを設定しました。\n",
    "\n",
    "        # --- Step 2d: Clean Column Names ---\n",
    "        # --- ステップ2d: カラム名のクリーンアップ ---\n",
    "        \n",
    "        # *** THIS IS THE FIX: ***\n",
    "        # *** これが修正点です： ***\n",
    "        # Force all column names to be strings *before* using .str\n",
    "        # .str を使う*前*に、すべてのカラム名を文字列に強制します\n",
    "        clean_df.columns = clean_df.columns.astype(str)\n",
    "        \n",
    "        clean_df.columns = clean_df.columns.str.strip()\n",
    "        clean_df.rename(columns=lambda x: re.sub(r'\\s\\d{1,2}:\\d{2}\\s[AP]M', '', x), inplace=True)\n",
    "        clean_df.columns = clean_df.columns.str.replace(' ', '_')\n",
    "        print(\"  Cleaned column names.\")\n",
    "        #   カラム名をクリーンアップしました。\n",
    "\n",
    "        # --- Step 2e: Add Metadata Columns ---\n",
    "        # --- ステップ2e: メタデータカラムの追加 ---\n",
    "        clean_df['Date'] = date_str\n",
    "        clean_df['Time_of_Reading'] = time_str\n",
    "        clean_df['Source_GID'] = target_gid\n",
    "        print(\"  Added metadata columns.\")\n",
    "        #   メタデータカラムを追加しました。\n",
    "\n",
    "        # --- Step 2f: Drop Empty Rows ---\n",
    "        # --- ステップ2f: 空の行の削除 ---\n",
    "        clean_df.dropna(subset=['Location'], inplace=True)\n",
    "        print(\"  Dropped empty rows.\")\n",
    "        #   空の行を削除しました。\n",
    "\n",
    "        # --- Step 2g: Final Polish (Type Conversion) ---\n",
    "        # --- ステップ2g: 最終仕上げ（型変換） ---\n",
    "        if 'Available_Spaces' in clean_df.columns:\n",
    "            clean_df['Available_Spaces'] = pd.to_numeric(clean_df['Available_Spaces'], errors='coerce')\n",
    "        clean_df['Date'] = pd.to_datetime(clean_df['Date'], errors='coerce')\n",
    "        print(\"  Converted data types.\")\n",
    "        #   データ型を変換しました。\n",
    "\n",
    "        # --- 3. Show Final Result ---\n",
    "        # --- 3. 最終結果の表示 ---\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"--- FINAL CLEANED DATA (First 10 Rows) ---\")\n",
    "        # --- 最終クリーンアップデータ（最初の10行）---\n",
    "        print(clean_df.head(10))\n",
    "        \n",
    "        print(\"\\n--- FINAL DATA INFO ---\")\n",
    "        # --- 最終データ情報 ---\n",
    "        clean_df.info()\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to download. Status code: {response.status_code}\")\n",
    "        # ダウンロードに失敗しました。ステータスコード: {response.status_code}\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    # エラーが発生しました: {e}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>2</th>\n",
       "      <th>Space_Type</th>\n",
       "      <th>nan</th>\n",
       "      <th>Location</th>\n",
       "      <th>8:00_AM</th>\n",
       "      <th>10:00_AM</th>\n",
       "      <th>12:00_PM</th>\n",
       "      <th>2:00_PM</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time_of_Reading</th>\n",
       "      <th>Source_GID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>Structure</td>\n",
       "      <td>8980</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>2025-09-25</td>\n",
       "      <td>8:00 AM</td>\n",
       "      <td>590671728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Athena</td>\n",
       "      <td>217</td>\n",
       "      <td>140</td>\n",
       "      <td>108</td>\n",
       "      <td>112</td>\n",
       "      <td>2025-09-25</td>\n",
       "      <td>8:00 AM</td>\n",
       "      <td>590671728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Campus Point East</td>\n",
       "      <td>94</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>2025-09-25</td>\n",
       "      <td>8:00 AM</td>\n",
       "      <td>590671728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Campus Point West</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-09-25</td>\n",
       "      <td>8:00 AM</td>\n",
       "      <td>590671728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gilman</td>\n",
       "      <td>326</td>\n",
       "      <td>120</td>\n",
       "      <td>44</td>\n",
       "      <td>45</td>\n",
       "      <td>2025-09-25</td>\n",
       "      <td>8:00 AM</td>\n",
       "      <td>590671728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Visitor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P510</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-25</td>\n",
       "      <td>8:00 AM</td>\n",
       "      <td>590671728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Visitor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P602</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-09-25</td>\n",
       "      <td>8:00 AM</td>\n",
       "      <td>590671728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Visitor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P603</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>2025-09-25</td>\n",
       "      <td>8:00 AM</td>\n",
       "      <td>590671728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Visitor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P703</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>2025-09-25</td>\n",
       "      <td>8:00 AM</td>\n",
       "      <td>590671728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Visitor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P752</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-25</td>\n",
       "      <td>8:00 AM</td>\n",
       "      <td>590671728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "2   Space_Type        nan           Location 8:00_AM 10:00_AM 12:00_PM  \\\n",
       "3            A  Structure               8980      25       23       19   \n",
       "4            A        NaN             Athena     217      140      108   \n",
       "5            A        NaN  Campus Point East      94       23       13   \n",
       "6            A        NaN  Campus Point West       1        0        0   \n",
       "7            A        NaN             Gilman     326      120       44   \n",
       "..         ...        ...                ...     ...      ...      ...   \n",
       "108    Visitor        NaN               P510       4        2        0   \n",
       "109    Visitor        NaN               P602       7        2        0   \n",
       "110    Visitor        NaN               P603      22       12        5   \n",
       "111    Visitor        NaN               P703       9       10        8   \n",
       "112    Visitor        NaN               P752       0        0        0   \n",
       "\n",
       "2   2:00_PM       Date Time_of_Reading Source_GID  \n",
       "3        20 2025-09-25         8:00 AM  590671728  \n",
       "4       112 2025-09-25         8:00 AM  590671728  \n",
       "5        17 2025-09-25         8:00 AM  590671728  \n",
       "6         1 2025-09-25         8:00 AM  590671728  \n",
       "7        45 2025-09-25         8:00 AM  590671728  \n",
       "..      ...        ...             ...        ...  \n",
       "108       0 2025-09-25         8:00 AM  590671728  \n",
       "109       1 2025-09-25         8:00 AM  590671728  \n",
       "110      12 2025-09-25         8:00 AM  590671728  \n",
       "111       9 2025-09-25         8:00 AM  590671728  \n",
       "112       0 2025-09-25         8:00 AM  590671728  \n",
       "\n",
       "[110 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['590671728', '1596814157', '0', '1732410273', '980526681', '1691861364', '1701491299', '1997138837', '1843964475', '871989841'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dataframes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading raw data for GID: 590671728...\n",
      "Raw data downloaded. Starting cleaning process...\n",
      "--- Cleaning GID 590671728 ---\n",
      "  Found Date: Thursday, September 25, 2025\n",
      "  Found Time: 8:00 AM\n",
      "  Found Header at row index: 2\n",
      "An error occurred: expected string or bytes-like object, got 'float'\n"
     ]
    }
   ],
   "source": [
    "def clean_and_restructure_data(df, gid):\n",
    "    \"\"\"\n",
    "    Cleans a single raw DataFrame from the Google Sheet.\n",
    "    - Finds and extracts the date and time.\n",
    "    - Finds the real header row.\n",
    "    - Returns a cleaned DataFrame.\n",
    "\n",
    "    Googleスプレッドシートから取得した生のDataFrameを1つクリーンアップします。\n",
    "    - 日付と時刻を見つけて抽出します。\n",
    "    - 実際のヘッダー行を見つけます。\n",
    "    - クリーンアップされたDataFrameを返します。\n",
    "    \"\"\"\n",
    "    print(f\"--- Cleaning GID {gid} ---\")\n",
    "    # --- GID {gid} をクリーニング中 ---\n",
    "    \n",
    "    # --- 1. Find Date and Time ---\n",
    "    # --- 1. 日付と時刻の検索 ---\n",
    "    date_str = None\n",
    "    time_str = None\n",
    "    header_row_index = None\n",
    "    \n",
    "    # Convert entire DataFrame to string to search for patterns\n",
    "    # パターン検索のためにDataFrame全体を文字列に変換します\n",
    "    df_string_dump = df.to_string()\n",
    "    \n",
    "    # Regex to find the date (e.g., \"Thursday, September 25, 2025\")\n",
    "    # 日付を見つけるための正規表現（例：「Thursday, September 25, 2025」）\n",
    "    date_match = re.search(r'(\\w+,\\s\\w+\\s\\d+,\\s\\d{4})', df_string_dump)\n",
    "    if date_match:\n",
    "        date_str = date_match.group(1)\n",
    "        print(f\"  Found Date: {date_str}\")\n",
    "        #   日付が見つかりました: {date_str}\n",
    "\n",
    "    # Regex to find the time (e.g., \"8:00 AM\")\n",
    "    # 時刻を見つけるための正規表現（例：「8:00 AM」）\n",
    "    time_match = re.search(r'(\\d{1,2}:\\d{2}\\s[AP]M)', df_string_dump)\n",
    "    if time_match:\n",
    "        time_str = time_match.group(1)\n",
    "        print(f\"  Found Time: {time_str}\")\n",
    "        #   時刻が見つかりました: {time_str}\n",
    "\n",
    "    # --- 2. Find the actual header row ---\n",
    "    # --- 2. 実際のヘッダー行の検索 ---\n",
    "    for i, row in df.iterrows():\n",
    "        if 'Location' in row.values:\n",
    "            header_row_index = i\n",
    "            print(f\"  Found Header at row index: {header_row_index}\")\n",
    "            #   ヘッダー行をインデックス: {header_row_index} で見つけました\n",
    "            break\n",
    "            \n",
    "    if header_row_index is None:\n",
    "        print(f\"  [ERROR] No header row (with 'Location') found for GID {gid}.\")\n",
    "        #   [エラー] GID {gid} のヘッダー行（'Location'を含む）が見つかりません。\n",
    "        return None # Skip this DataFrame\n",
    "\n",
    "    # --- 3. Create the new, clean DataFrame ---\n",
    "    # --- 3. 新しいクリーンなDataFrameの作成 ---\n",
    "    \n",
    "    # Set the new header\n",
    "    # 新しいヘッダーを設定\n",
    "    new_header = df.iloc[header_row_index]\n",
    "    clean_df = df[header_row_index + 1:].copy() # Get all data below the header\n",
    "    clean_df.columns = new_header\n",
    "    \n",
    "    # Clean column names (e.g., \"Available Spaces 8:00 AM\" -> \"Available_Spaces\")\n",
    "    # カラム名をクリーンアップ（例：「Available Spaces 8:00 AM」->「Available_Spaces」）\n",
    "    clean_df.columns = clean_df.columns.str.strip() # Remove whitespace\n",
    "    clean_df.rename(columns=lambda x: re.sub(r'\\s\\d{1,2}:\\d{2}\\s[AP]M', '', x), inplace=True)\n",
    "    clean_df.columns = clean_df.columns.str.replace(' ', '_')\n",
    "    \n",
    "    # Add the extracted metadata\n",
    "    # 抽出したメタデータを追加\n",
    "    clean_df['Date'] = date_str\n",
    "    clean_df['Time_of_Reading'] = time_str\n",
    "    clean_df['Source_GID'] = gid\n",
    "    \n",
    "    # Drop empty rows (where 'Location' is NaN)\n",
    "    # 空の行（'Location'がNaN）を削除\n",
    "    clean_df.dropna(subset=['Location'], inplace=True)\n",
    "    \n",
    "    # --- 4. Final Polish ---\n",
    "    # --- 4. 最終仕上げ ---\n",
    "    \n",
    "    # Convert types\n",
    "    # 型を変換\n",
    "    if 'Available_Spaces' in clean_df.columns:\n",
    "         clean_df['Available_Spaces'] = pd.to_numeric(clean_df['Available_Spaces'], errors='coerce')\n",
    "    clean_df['Date'] = pd.to_datetime(clean_df['Date'], errors='coerce')\n",
    "    \n",
    "    print(f\"  [SUCCESS] Cleaning complete for GID {gid}.\")\n",
    "    #   [成功] GID {gid} のクリーニングが完了しました。\n",
    "    \n",
    "    return clean_df\n",
    "\n",
    "# --- Main part of the script ---\n",
    "# --- スクリプトのメイン部分 ---\n",
    "\n",
    "# This is the GID we want to test\n",
    "# これがテストしたいGIDです\n",
    "target_gid = '590671728'\n",
    "# This is the *Sheet ID* from the URL\n",
    "# これはURLからの*シートID*です\n",
    "sheet_id = '1OscrXVHgOn75NrsrUxJfitmcPBHRj6xlnRcsq9jXo2g'\n",
    "\n",
    "# Build the download URL\n",
    "# ダウンロードURLを構築\n",
    "download_url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&gid={target_gid}\"\n",
    "\n",
    "print(f\"Downloading raw data for GID: {target_gid}...\")\n",
    "# GID: {target_gid} の生データをダウンロード中...\n",
    "\n",
    "try:\n",
    "    # 1. Download the raw data\n",
    "    # 1. 生データをダウンロード\n",
    "    response = requests.get(download_url)\n",
    "    if response.status_code == 200:\n",
    "        csv_content = response.content.decode('utf-8')\n",
    "        csv_file = io.StringIO(csv_content)\n",
    "        \n",
    "        # Read with no header, just like in the full script\n",
    "        # 完全なスクリプトと同様に、ヘッダーなしで読み込みます\n",
    "        raw_df = pd.read_csv(csv_file, header=None)\n",
    "        \n",
    "        print(\"Raw data downloaded. Starting cleaning process...\")\n",
    "        # 生データをダウンロードしました。クリーニングプロセスを開始します...\n",
    "\n",
    "        # 2. Call the cleaning function on this one DataFrame\n",
    "        # 2. この1つのDataFrameに対してクリーニング関数を呼び出します\n",
    "        cleaned_dataframe = clean_and_restructure_data(raw_df, target_gid)\n",
    "        \n",
    "        if cleaned_dataframe is not None:\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(\"--- Cleaned DataFrame (First 10 Rows) ---\")\n",
    "            # --- クリーンアップされたDataFrame（最初の10行）---\n",
    "            print(cleaned_dataframe.head(10))\n",
    "            \n",
    "            print(\"\\n--- Cleaned DataFrame Info ---\")\n",
    "            # --- クリーンアップされたDataFrameの情報 ---\n",
    "            cleaned_dataframe.info()\n",
    "        else:\n",
    "            print(\"Cleaning failed.\")\n",
    "            # クリーニングに失敗しました。\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to download. Status code: {response.status_code}\")\n",
    "        # ダウンロードに失敗しました。ステータスコード: {response.status_code}\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching main page: https://transportation.ucsd.edu/commute/permits/availability.html\n",
      "Successfully fetched main page.\n",
      "Found 12 <iframe> tags. Filtering for Google Sheets...\n",
      "  Warning: Could not find Week/Day for GID 590671728. Using default name.\n",
      "  Warning: Could not find Week/Day for GID 1596814157. Using default name.\n",
      "  Warning: Could not find Week/Day for GID 0. Using default name.\n",
      "  Warning: Could not find Week/Day for GID 1732410273. Using default name.\n",
      "  Warning: Could not find Week/Day for GID 980526681. Using default name.\n",
      "  Warning: Could not find Week/Day for GID 1691861364. Using default name.\n",
      "  Warning: Could not find Week/Day for GID 1701491299. Using default name.\n",
      "  Warning: Could not find Week/Day for GID 1997138837. Using default name.\n",
      "  Warning: Could not find Week/Day for GID 1843964475. Using default name.\n",
      "  Warning: Could not find Week/Day for GID 871989841. Using default name.\n",
      "  Warning: Could not find Week/Day for GID 1378029010. Using default name.\n",
      "  Warning: Could not find Week/Day for GID 293064621. Using default name.\n",
      "Found 12 unique Google Sheet tabs to download.\n",
      "\n",
      "Downloading: GID_590671728.csv (GID: 590671728)\n",
      "  [SUCCESS] Saved file: GID_590671728.csv\n",
      "\n",
      "Downloading: GID_1596814157.csv (GID: 1596814157)\n",
      "  [SUCCESS] Saved file: GID_1596814157.csv\n",
      "\n",
      "Downloading: GID_0.csv (GID: 0)\n",
      "  [SUCCESS] Saved file: GID_0.csv\n",
      "\n",
      "Downloading: GID_1732410273.csv (GID: 1732410273)\n",
      "  [SUCCESS] Saved file: GID_1732410273.csv\n",
      "\n",
      "Downloading: GID_980526681.csv (GID: 980526681)\n",
      "  [SUCCESS] Saved file: GID_980526681.csv\n",
      "\n",
      "Downloading: GID_1691861364.csv (GID: 1691861364)\n",
      "  [SUCCESS] Saved file: GID_1691861364.csv\n",
      "\n",
      "Downloading: GID_1701491299.csv (GID: 1701491299)\n",
      "  [SUCCESS] Saved file: GID_1701491299.csv\n",
      "\n",
      "Downloading: GID_1997138837.csv (GID: 1997138837)\n",
      "  [SUCCESS] Saved file: GID_1997138837.csv\n",
      "\n",
      "Downloading: GID_1843964475.csv (GID: 1843964475)\n",
      "  [SUCCESS] Saved file: GID_1843964475.csv\n",
      "\n",
      "Downloading: GID_871989841.csv (GID: 871989841)\n",
      "  [SUCCESS] Saved file: GID_871989841.csv\n",
      "\n",
      "Downloading: GID_1378029010.csv (GID: 1378029010)\n",
      "  [FAILED] Could not download GID_1378029010.csv. Status: 404\n",
      "\n",
      "Downloading: GID_293064621.csv (GID: 293064621)\n",
      "  [FAILED] Could not download GID_293064621.csv. Status: 404\n",
      "\n",
      "==================================================\n",
      "Scraping complete.\n",
      "Successfully saved 10 files.\n",
      "The files are in the same directory as this script.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "import time\n",
    "from bs4 import BeautifulSoup # You'll need to install this: pip install beautifulsoup4\n",
    "import re\n",
    "import os # <-- Added for saving files\n",
    "\n",
    "# --- 1. Scrape the main page to find all the Google Sheet links ---\n",
    "\n",
    "main_url = \"https://transportation.ucsd.edu/commute/permits/availability.html\"\n",
    "\n",
    "# This dictionary will hold all our data\n",
    "# We'll now store (csv_url, filename)\n",
    "csv_links = {}\n",
    "\n",
    "print(f\"Fetching main page: {main_url}\")\n",
    "\n",
    "try:\n",
    "    main_page_response = requests.get(main_url)\n",
    "    \n",
    "    if main_page_response.status_code == 200:\n",
    "        print(\"Successfully fetched main page.\")\n",
    "        \n",
    "        soup = BeautifulSoup(main_page_response.content, 'html.parser')\n",
    "        \n",
    "        iframes = soup.find_all('iframe')\n",
    "        \n",
    "        print(f\"Found {len(iframes)} <iframe> tags. Filtering for Google Sheets...\")\n",
    "\n",
    "        for frame in iframes:\n",
    "            src_link = frame.get('src')\n",
    "            \n",
    "            if src_link and 'docs.google.com/spreadsheets' in src_link and '/pubhtml' in src_link:\n",
    "                \n",
    "                # --- 2. Convert the /pubhtml link to a /export?format=csv link ---\n",
    "                \n",
    "                sheet_id_match = re.search(r'/d/([a-zA-Z0-9-_]+)', src_link)\n",
    "                gid_match = re.search(r'gid=([0-9]+)', src_link)\n",
    "                \n",
    "                if sheet_id_match and gid_match:\n",
    "                    sheet_id = sheet_id_match.group(1)\n",
    "                    gid = gid_match.group(1)\n",
    "                    \n",
    "                    csv_url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&gid={gid}\"\n",
    "                    \n",
    "                    # --- NEW: Find Week and Day for filename ---\n",
    "                    filename = f\"GID_{gid}.csv\" # Default name\n",
    "                    try:\n",
    "                        # Climb up to the 'drawer' div to find the day\n",
    "                        day_drawer = frame.find_parent('div', class_='drawer')\n",
    "                        day_heading = day_drawer.find('h2', class_='expand')\n",
    "                        day_name = day_heading.get_text(strip=True)\n",
    "                        \n",
    "                        # Climb up to the 'drawer-wrapper' to find the week\n",
    "                        drawer_wrapper = day_drawer.find_parent('div', class_='drawer-wrapper')\n",
    "                        week_heading = drawer_wrapper.find_previous_sibling('h2')\n",
    "                        week_name = week_heading.get_text(strip=True)\n",
    "\n",
    "                        # Sanitize names for a clean filename\n",
    "                        safe_week = re.sub(r'\\W+', '_', week_name)\n",
    "                        safe_day = re.sub(r'\\W+', '_', day_name)\n",
    "                        filename = f\"{safe_week}-{safe_day}.csv\"\n",
    "                        \n",
    "                        print(f\"  Found file: {filename}\")\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"  Warning: Could not find Week/Day for GID {gid}. Using default name.\")\n",
    "                    \n",
    "                    # Add it to our list, using the GID as a key to avoid duplicates\n",
    "                    if gid not in csv_links:\n",
    "                        csv_links[gid] = (csv_url, filename)\n",
    "\n",
    "        print(f\"Found {len(csv_links)} unique Google Sheet tabs to download.\")\n",
    "\n",
    "        # --- 3. Loop, Download, and SAVE each CSV ---\n",
    "        files_saved_count = 0\n",
    "        for gid, (download_url, filename) in csv_links.items():\n",
    "            \n",
    "            print(f\"\\nDownloading: {filename} (GID: {gid})\")\n",
    "            \n",
    "            try:\n",
    "                response = requests.get(download_url)\n",
    "                if response.status_code == 200:\n",
    "                    \n",
    "                    # --- THIS IS THE NEW FILE WRITING PART ---\n",
    "                    # We save the raw content, not a pandas DataFrame,\n",
    "                    # as this is more reliable.\n",
    "                    with open(filename, 'wb') as f:\n",
    "                        f.write(response.content)\n",
    "                    \n",
    "                    print(f\"  [SUCCESS] Saved file: {filename}\")\n",
    "                    files_saved_count += 1\n",
    "                    \n",
    "                else:\n",
    "                    print(f\"  [FAILED] Could not download {filename}. Status: {response.status_code}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"  [FAILED] An error occurred for {filename}: {e}\")\n",
    "            \n",
    "            time.sleep(1) # Be polite\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to fetch main page. Status code: {main_page_response.status_code}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Scraping complete.\")\n",
    "print(f\"Successfully saved {files_saved_count} files.\")\n",
    "print(\"The files are in the same directory as this script.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting file renaming process...\n",
      "Found 10 files to rename.\n",
      "  Renamed: GID_980526681.csv  ->  Parking_Occupancy_Fall_2025_Week1_Wednesday.csv\n",
      "  Renamed: GID_1732410273.csv  ->  Parking_Occupancy_Fall_2025_Week1_Tuesday.csv\n",
      "  Renamed: GID_1691861364.csv  ->  Parking_Occupancy_Fall_2025_Week1_Thursday.csv\n",
      "  Renamed: GID_0.csv  ->  Parking_Occupancy_Fall_2025_Week1_Monday.csv\n",
      "  Renamed: GID_1701491299.csv  ->  Parking_Occupancy_Fall_2025_Week1_Friday.csv\n",
      "  Renamed: GID_1596814157.csv  ->  Parking_Occupancy_Fall_2025_Week0_Friday.csv\n",
      "  Renamed: GID_590671728.csv  ->  Parking_Occupancy_Fall_2025_Week0_Thursday.csv\n",
      "  Renamed: GID_1997138837.csv  ->  Parking_Occupancy_Fall_2025_Week2_Monday.csv\n",
      "  Renamed: GID_871989841.csv  ->  Parking_Occupancy_Fall_2025_Week2_Wednesday.csv\n",
      "  Renamed: GID_1843964475.csv  ->  Parking_Occupancy_Fall_2025_Week2_Tuesday.csv\n",
      "\n",
      "Renaming complete. Successfully renamed 10 files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "\n",
    "print(\"Starting file renaming process...\")\n",
    "\n",
    "# Find all files starting with 'GID_' and ending with '.csv'\n",
    "# in the current directory\n",
    "files_to_rename = glob.glob('GID_*.csv')\n",
    "\n",
    "if not files_to_rename:\n",
    "    print(\"No 'GID_*.csv' files found in this directory.\")\n",
    "    print(\"Please make sure this script is in the same folder as your CSV files.\")\n",
    "else:\n",
    "    print(f\"Found {len(files_to_rename)} files to rename.\")\n",
    "\n",
    "renamed_count = 0\n",
    "for old_filename in files_to_rename:\n",
    "    try:\n",
    "        with open(old_filename, 'r') as f:\n",
    "            # Read the first two lines which contain the info\n",
    "            line1 = f.readline()\n",
    "            line2 = f.readline()\n",
    "        \n",
    "        # --- Extract Information ---\n",
    "        \n",
    "        # From Line 1: \"Parking Occupancy : Fall 2025 Week 2,,,,,,\"\n",
    "        week_match = re.search(r'Week (\\d+)', line1)\n",
    "        \n",
    "        # From Line 2: \"\"Wednesday, October 8, 2025\",,,Available Spaces,,,\"\n",
    "        day_match = re.search(r'\"(\\w+),', line2)\n",
    "        \n",
    "        if week_match and day_match:\n",
    "            week_number = week_match.group(1)\n",
    "            day_name = day_match.group(1)\n",
    "            \n",
    "            # --- Construct New Filename ---\n",
    "            new_filename = f\"Parking_Occupancy_Fall_2025_Week{week_number}_{day_name}.csv\"\n",
    "            \n",
    "            # --- Rename the File ---\n",
    "            os.rename(old_filename, new_filename)\n",
    "            print(f\"  Renamed: {old_filename}  ->  {new_filename}\")\n",
    "            renamed_count += 1\n",
    "        else:\n",
    "            print(f\"  Skipping: {old_filename} (Could not find Week/Day info)\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  Error renaming {old_filename}: {e}\")\n",
    "\n",
    "print(f\"\\nRenaming complete. Successfully renamed {renamed_count} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolio_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
